{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\n",
      "100.0 %\n",
      "99.595 %\n",
      "96.345 %\n",
      "98.88 %\n",
      "99.505 %\n",
      "99.53999999999999 %\n",
      "99.3 %\n",
      "95.535 %\n",
      "98.91 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "from scipy.stats import skew, kurtosis\n",
    "from statistics import mean, variance, stdev\n",
    "import statsmodels.tsa.stattools as ts #Statistical tools for time series analysis\n",
    "import multiprocessing\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "USER_IDS=[1,2,3,4,5,6,7,8,9,10]\n",
    "ACCEL_IDS=[i for i in range(1,301)]\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def get_accel(user_id, accel_id, folder):   \n",
    "    filename = '%s/%s/%s.csv' % (folder, 'user'+str(user_id), 'accelerometer_'+str(accel_id))\n",
    "    COLUMNS = ['timestamp', 'xAxis', 'yAxis', 'zAxis']\n",
    "    df = pd.read_csv(filename,header=None, names=COLUMNS)\n",
    "    accel=[[df.iloc[i,0],df.iloc[i,1],df.iloc[i,2],df.iloc[i,3]] for i in range(len(df))][:142]\n",
    "    return accel \n",
    "\n",
    "def get_accels(user_id, folder):\n",
    "    if folder =='train':\n",
    "        for accel_id in range(1, 201):\n",
    "            yield get_accel(user_id, accel_id, folder)\n",
    "    elif folder=='test':\n",
    "        for accel_id in range(201, 301):\n",
    "            yield get_accel(user_id, accel_id, folder)\n",
    "        \n",
    "def get_random_accels(user_id, folder):\n",
    "    users=[i for i in range(1,11)]\n",
    "    users.remove(user_id)\n",
    "    if folder =='train':\n",
    "        for user_id in users:\n",
    "            accel_ids = np.random.choice(np.arange(1,201), 23, replace=False)\n",
    "            accel_ids=list(accel_ids)\n",
    "            for accel_id in accel_ids:\n",
    "                yield get_accel(user_id, accel_id, folder)\n",
    "    elif  folder=='test':\n",
    "        for user_id in users:\n",
    "            accel_ids = np.random.choice(np.arange(201,301), 12, replace=False)\n",
    "            accel_ids=list(accel_ids)\n",
    "            for accel_id in accel_ids:\n",
    "                yield get_accel(user_id, accel_id, folder)\n",
    "    \n",
    "#print(len(list(get_random_accels(1, 'train'))))      23*9=207 accels randomly sampled from the other users     \n",
    "#print(len(list(get_random_accels(1, 'test'))))      12*9=108 accels randomly sampled from the other users          \n",
    "        \n",
    "def plot_axis(ax, x, y, title):\n",
    "    ax.plot(x, y)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
    "    ax.set_xlim([min(x), max(x)])\n",
    "    ax.grid(True)\n",
    "    \n",
    "def plot_accel(user_id, accel_id, folder):\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(15, 10), sharex=True)\n",
    "    filename = '%s/%s/%s.csv' % (folder, 'user'+str(user_id), 'accelerometer_'+str(accel_id))\n",
    "    COLUMNS = ['timestamp', 'xAxis', 'yAxis', 'zAxis']\n",
    "    df = pd.read_csv(filename,header=None, names=COLUMNS)\n",
    "    plot_axis(ax0, df['timestamp'], df['xAxis'], 'x Axis')\n",
    "    plot_axis(ax1, df['timestamp'], df['yAxis'], 'y Axis')\n",
    "    plot_axis(ax2, df['timestamp'], df['zAxis'], 'z Axis')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def magnitude_acc(accel):\n",
    "    magn=[]\n",
    "    for i in range(len(accel)):\n",
    "        m2=accel[i][1]**2+accel[i][2]**2+accel[i][3]**2\n",
    "        magn.append(math.sqrt(m2))\n",
    "    return magn\n",
    "                   \n",
    "#print(magnitude_acc(get_accel(user_id, accel_id, folder)))\n",
    "                   \n",
    "def windows(df, size=30):\n",
    "    start = 0\n",
    "    while (start+size) < len(df):\n",
    "        yield start, start + size\n",
    "        start += (size / 2)\n",
    "\n",
    "     \n",
    "def jitter(axis, start, end):\n",
    "    j =float(0)\n",
    "    for k in range(start, min(end, len(axis))):\n",
    "        if start> 0:\n",
    "            j =j+ abs(axis[k] - axis[k-1])\n",
    "    return j/float(end-start)\n",
    "\n",
    "def mean_crossing_rate(axis, start, end):\n",
    "    cr = 0\n",
    "    m = mean(axis)\n",
    "    for i in range(start, min(end, len(axis))):\n",
    "        if start> 0:\n",
    "            p = axis[i-1] > m\n",
    "            c = axis[i] > m\n",
    "            if p != c:\n",
    "                cr += 1\n",
    "    return float(cr) /(end-start-1)\n",
    "\n",
    "def window_summary(axis, start, end):\n",
    "    start=int(start)\n",
    "    end=int(end)\n",
    "    #acf = ts.acf(np.array(axis[start:end]))  #auto correlation\n",
    "    #acv = ts.acovf(np.array(axis[start:end]))  #auto covariance\n",
    "    return [\n",
    "        #jitter(axis, start, end),     \n",
    "        mean_crossing_rate(axis, start, end),\n",
    "        mean(axis[start:end]),\n",
    "        stdev(axis[start:end]),\n",
    "        variance(axis[start:end]),\n",
    "        min(axis[start:end]),\n",
    "        max(axis[start:end]),\n",
    "        #acf.mean(), # mean auto correlation\n",
    "        #acf.std(), # standard deviation auto correlation\n",
    "        #acv.mean(), # mean auto covariance\n",
    "        #acv.std(), # standard deviation auto covariance\n",
    "        skew(axis[start:end]),\n",
    "        kurtosis(axis[start:end]) \n",
    "    ]\n",
    "\n",
    "def build_features(accel):\n",
    "    timestamps=[]\n",
    "    xAxis=[]\n",
    "    yAxis=[]\n",
    "    zAxis=[]\n",
    "    for i in range(len(accel)):\n",
    "        timestamps.append(accel[i][0])\n",
    "        xAxis.append(accel[i][1])\n",
    "        yAxis.append(accel[i][2])\n",
    "        zAxis.append(accel[i][3])\n",
    "    features=[]\n",
    "    for (start, end) in windows(timestamps):\n",
    "        start=int(start)\n",
    "        end=int(end)\n",
    "        features += window_summary(xAxis, start, end)\n",
    "        features += window_summary(yAxis, start, end)\n",
    "        features += window_summary(zAxis, start, end)\n",
    "    return features                   \n",
    "\n",
    "def get_data(user_id):\n",
    "    list1=list(get_accels(user_id, 'train'))  #first 200 observations of the training set\n",
    "    list2=list(get_random_accels(user_id, 'train'))[:-7]  #second 200 observations of the training set\n",
    "    list12=list1+list2   #all 400 observations of the training set \n",
    "    list1 = [build_features(accel) for accel in list12]  #features for each observation of the training set\n",
    "    \n",
    "    list3=list(get_accels(user_id,'test'))  #first 100 observations of the testing set\n",
    "    list4=list(get_random_accels(user_id, 'test'))[:-8]  #second 100 observations of the testing set\n",
    "    list34=list3+list4   #all 200 observations of the testing set \n",
    "    list2 = [build_features(accel) for accel in list34]  #features for each observation of the testing set\n",
    "    return list1,list2\n",
    "\n",
    "def run_model(user_id, Model): \n",
    "    trainX, testX=get_data(user_id) \n",
    "    trainY = [1]*200 + [0]*200  #labels with 1 for the correct user and 0 for the incorrect user in training\n",
    "    testY = [1]*100 + [0]*100  #labels with 1 for the correct user and 0 for the incorrect user in testing\n",
    "    model = Model.fit(trainX, trainY)\n",
    "    predictions = model.predict_proba(testX)[:,1] #probability estimates of the positive class\n",
    "    return testY, predictions\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #Model = GradientBoostingClassifier(n_estimators=500,learning_rate=1,max_depth=5,random_state=0)\n",
    "    Model = RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "    #results=[]\n",
    "    #for i in range(1,11):\n",
    "    #    results.extend(list(run_model(i, Model)))\n",
    "    for i in range(1,11):\n",
    "        testY,predictions=run_model(i, Model)\n",
    "        fpr, tpr, thresholds = roc_curve(testY, predictions)\n",
    "        #print('predictions=', predictions)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(roc_auc*100, '%')\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "                   \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
